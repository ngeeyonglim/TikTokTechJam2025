{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI5V998cwhCA",
        "outputId": "9be16686-652b-4652-fdfa-71a982b5db4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/mnt; to attempt to forcibly remount, call drive.mount(\"/content/mnt\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opacus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCiarZ4HwjLz",
        "outputId": "668b0d92-60da-402e-9f1b-41e442bb2837"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opacus in /usr/local/lib/python3.12/dist-packages (1.5.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.12/dist-packages (from opacus) (1.16.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from opacus) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->opacus) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->opacus) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->opacus) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "import copy\n",
        "import math"
      ],
      "metadata": {
        "id": "oW3UgjZT4M8x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FederatedClient:\n",
        "    def __init__(self, client_id, model, train_data, dp_config=None, device='cpu'):\n",
        "        self.client_id = client_id\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "        self.train_data = train_data\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.05)\n",
        "        self.dp_enabled = dp_config is not None\n",
        "\n",
        "        if self.dp_enabled:\n",
        "            # wrap optimizer with Opacus PrivacyEngine\n",
        "            self.privacy_engine = PrivacyEngine()\n",
        "            self.model, self.optimizer, self.train_data = self.privacy_engine.make_private(\n",
        "                module=self.model,\n",
        "                optimizer=self.optimizer,\n",
        "                data_loader=self.train_data,\n",
        "                noise_multiplier=dp_config.get(\"noise_multiplier\", 1.2),\n",
        "                max_grad_norm=dp_config.get(\"max_grad_norm\", 1.0),\n",
        "            )\n",
        "\n",
        "    def local_train(self, epochs=1):\n",
        "        self.model.train()\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            for data, target in self.train_data:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "        # Calculate model updates\n",
        "        return (self.model._module if self.dp_enabled else self.model).state_dict()"
      ],
      "metadata": {
        "id": "MOGeNa1X9S8s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FederatedServer:\n",
        "    def __init__(self, global_model, device='cpu'):\n",
        "        self.global_model = global_model\n",
        "        self.clients = []\n",
        "        self.round = 0\n",
        "        self.device = device\n",
        "\n",
        "    def add_client(self, client):\n",
        "        self.clients.append(client)\n",
        "\n",
        "    def federated_round(self, local_epochs=1):\n",
        "        client_updates = []\n",
        "\n",
        "        for client in self.clients:\n",
        "            # sync global weights to clients\n",
        "            client_model_state = self.global_model.state_dict()\n",
        "            if client.dp_enabled:\n",
        "                client.model._module.load_state_dict(client_model_state)\n",
        "            else:\n",
        "                client.model.load_state_dict(client_model_state)\n",
        "            update = client.local_train(local_epochs)\n",
        "            client_updates.append(update)\n",
        "\n",
        "        # Aggregate with averaging\n",
        "        aggregated_state = {}\n",
        "        num_clients = len(client_updates)\n",
        "        for name in client_updates[0]:\n",
        "            stacked = torch.stack([u[name].to(self.device) for u in client_updates])\n",
        "            aggregated_state[name] = torch.mean(stacked, dim=0).to(self.device)\n",
        "\n",
        "        # Update global model\n",
        "        self.global_model.load_state_dict(aggregated_state)\n",
        "        self.round += 1"
      ],
      "metadata": {
        "id": "sZcnh-4n_geA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_csv(path):\n",
        "    \"\"\"\n",
        "    Load MNIST-like CSV file (label in col 0, pixels in cols 1:785).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, header=None).values\n",
        "    y = torch.tensor(df[:, 0].astype(np.int64))\n",
        "    X = torch.tensor(df[:, 1:].astype(np.float32))\n",
        "    X = X / 255.0\n",
        "    return X, y\n",
        "\n",
        "def make_test_loader(path=\"/content/sample_data/mnist_test.csv\", batch_size=256):\n",
        "    X, y = load_mnist_csv(path)\n",
        "    test_ds = TensorDataset(X, y)\n",
        "    return DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def make_federated_loaders(\n",
        "    num_clients=3,\n",
        "    batch_size=64,\n",
        "    shuffle_seed=42,\n",
        "    path=\"/content/sample_data/mnist_train_small.csv\",\n",
        "    test_path=\"/content/sample_data/mnist_test.csv\"\n",
        "):\n",
        "    X, y = load_mnist_csv(path)\n",
        "\n",
        "    # Create test loader from external test set\n",
        "    test_loader = make_test_loader(test_path, batch_size=256)\n",
        "\n",
        "    # Partition training data evenly across clients\n",
        "    n = len(X)\n",
        "    per_client = math.ceil(n / num_clients)\n",
        "    order = np.random.RandomState(shuffle_seed).permutation(n)\n",
        "\n",
        "    client_loaders = []\n",
        "    dataset = TensorDataset(X, y)\n",
        "\n",
        "    for c in range(num_clients):\n",
        "        start, end = c * per_client, min((c + 1) * per_client, n)\n",
        "        if start >= end:\n",
        "            break\n",
        "        subset_idx = order[start:end]\n",
        "        subset = Subset(dataset, subset_idx.tolist())\n",
        "        loader = DataLoader(subset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "        client_loaders.append(loader)\n",
        "\n",
        "    return client_loaders, test_loader\n"
      ],
      "metadata": {
        "id": "y5XzAM45_iaJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, device=None):\n",
        "    model.eval()\n",
        "    device = device or next(model.parameters()).device\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "m8-usYSRDUZr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=800, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ssr7tusBDVsq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    dp_config = {\n",
        "        \"noise_multiplier\": 1.2,\n",
        "        \"max_grad_norm\": 1.0,\n",
        "    }\n",
        "\n",
        "    global_model = SimpleNN().to(device)\n",
        "    server = FederatedServer(global_model, device=device)\n",
        "\n",
        "    # split train/test\n",
        "    client_data, test_loader = make_federated_loaders(num_clients=4,\n",
        "                                                      batch_size=64,\n",
        "                                                      shuffle_seed=42)\n",
        "\n",
        "    for client_id, train_data in enumerate(client_data):\n",
        "        # Each client gets a copy of the global model\n",
        "        client_model = copy.deepcopy(global_model).to(device)\n",
        "        # Set dp_config to None to train without Differential Privacy\n",
        "        client = FederatedClient(client_id, client_model, train_data, dp_config=None, device=device)\n",
        "        server.add_client(client)\n",
        "\n",
        "    # Run FL rounds\n",
        "    for r in range(10):\n",
        "        print(f\"\\n--- Federated Round {r+1} ---\")\n",
        "        server.federated_round(local_epochs=2)\n",
        "        acc = evaluate(server.global_model, test_loader, device=device)\n",
        "        print(f\"Test Accuracy after round {r+1}: {acc:.4f}\")\n",
        "\n",
        "    print(\"\\n Federated learning with differential privacy complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra-L443zDWV7",
        "outputId": "23b3489d-07a5-440f-829c-c81bbbd94030"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "--- Federated Round 1 ---\n",
            "Test Accuracy after round 1: 0.7354\n",
            "\n",
            "--- Federated Round 2 ---\n",
            "Test Accuracy after round 2: 0.8079\n",
            "\n",
            "--- Federated Round 3 ---\n",
            "Test Accuracy after round 3: 0.8492\n",
            "\n",
            "--- Federated Round 4 ---\n",
            "Test Accuracy after round 4: 0.8649\n",
            "\n",
            "--- Federated Round 5 ---\n",
            "Test Accuracy after round 5: 0.8766\n",
            "\n",
            "--- Federated Round 6 ---\n",
            "Test Accuracy after round 6: 0.8853\n",
            "\n",
            "--- Federated Round 7 ---\n",
            "Test Accuracy after round 7: 0.8901\n",
            "\n",
            "--- Federated Round 8 ---\n",
            "Test Accuracy after round 8: 0.8934\n",
            "\n",
            "--- Federated Round 9 ---\n",
            "Test Accuracy after round 9: 0.8961\n",
            "\n",
            "--- Federated Round 10 ---\n",
            "Test Accuracy after round 10: 0.8994\n",
            "\n",
            " Federated learning with differential privacy complete.\n"
          ]
        }
      ]
    }
  ]
}